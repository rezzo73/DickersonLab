{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates final reports for external use.\n",
    "\n",
    "**MAKE SURE THAT ALL LONI SPREADSHEETS ARE DOWNLOADED/UPDATED BEFORE RUNNING THIS SCRIPT**\n",
    "\n",
    "---------------------------- for data sharing with other sites ------------------------\n",
    "EXTERNAL REPORT CAN BE FOUND AT: /autofs/cluster/animal/scan_data/leads/spreadsheets/EXTERNAL\n",
    "\n",
    "------------------------------- for redcap importing ----------------------------------\n",
    "INTERNAL REPORT CAN BE FOUND AT: /autofs/cluster/animal/scan_data/leads/spreadsheets/INTERNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "scandir = '/autofs/cluster/animal/scan_data/leads/recon_nip/SCAN_NOTES/'\n",
    "internalpath = '/autofs/cluster/animal/scan_data/leads/spreadsheets/INTERNAL/'\n",
    "externalpath = '/autofs/cluster/animal/scan_data/leads/spreadsheets/EXTERNAL/'\n",
    "internal_dict = internalpath+'REDCAP_INSTRUMENT/LEADS_DataDictionary_2019-05-14.csv'\n",
    "external_dict = pd.read_csv(externalpath+'MGH_LEADS_datadictionary_3T_20190422.csv')\n",
    "file_derivelist = pd.read_csv('/autofs/homes/002/rje11/Desktop/LEADS_QC_Cumulative_20190701_1529.csv')\n",
    "# treat AMY STATUS as a static variable (scan dates will not match up, and no evidence of scr/baseline for MR tracking)\n",
    "AMYSTATUS_df = pd.read_csv('/autofs/cluster/animal/scan_data/leads/spreadsheets/LONI_PETINFO/LEADS_AMYELG.csv')\n",
    "DOWNLOADS_df = pd.read_csv('/autofs/cluster/animal/scan_data/leads/spreadsheets/LONI_DOWNLOADS/combined_downloads.csv')\n",
    "RECON3T_QC = pd.read_csv('/autofs/cluster/animal/scan_data/leads/recon_nip/RECON_3T/recon_notes.csv')\n",
    "\n",
    "# stats\n",
    "statsdir = '/autofs/cluster/animal/scan_data/leads/analyses_nip/RECON_3T/GROUPSTATS/'\n",
    "stats_asegmean = pd.read_table(statsdir+'leads_aseg_mean_auto.csv', sep=',',index_col=0)\n",
    "stats_asegvol = pd.read_table(statsdir+'leads_aseg_volume_auto.csv', sep=',',index_col=0)\n",
    "stats_aseg_std = pd.read_table(statsdir+'leads_aseg_std_auto.csv', sep=',',index_col=0)\n",
    "\n",
    "# rename col headers for aseg (too ambiguous)\n",
    "stats_asegmean.columns = [str(col) + '_aseg_mean' for col in stats_asegmean.columns]\n",
    "stats_asegvol.columns = [str(col) + '_aseg_volume' for col in stats_asegvol.columns]\n",
    "stats_aseg_std.columns = [str(col) + '_aseg_std' for col in stats_aseg_std.columns]\n",
    "\n",
    "stats_rh_aparc_vol = pd.read_table(statsdir+'leads_rh_aparc_volume_auto.csv', sep=',',index_col=0)\n",
    "stats_rh_aparc_area = pd.read_table(statsdir+'leads_rh_aparc_area_auto.csv', sep=',',index_col=0)\n",
    "stats_rh_aparc_thickness = pd.read_table(statsdir+'leads_rh_aparc_thickness_auto.csv', sep=',',index_col=0)\n",
    "stats_rh_aparc_thicknessstd = pd.read_table(statsdir+'leads_rh_aparc_thicknessstd_auto.csv', sep=',',index_col=0)\n",
    "stats_lh_aparc_vol = pd.read_table(statsdir+'leads_lh_aparc_volume_auto.csv', sep=',',index_col=0)\n",
    "stats_lh_aparc_area = pd.read_table(statsdir+'leads_lh_aparc_area_auto.csv', sep=',',index_col=0)\n",
    "stats_lh_aparc_thickness = pd.read_table(statsdir+'leads_lh_aparc_thickness_auto.csv', sep=',',index_col=0)\n",
    "stats_lh_aparc_thicknessstd = pd.read_table(statsdir+'leads_lh_aparc_thicknessstd_auto.csv', sep=',',index_col=0)\n",
    "\n",
    "stats_rh_aparc_vol.columns = [str(col) + '_aparc' for col in stats_rh_aparc_vol.columns]\n",
    "stats_lh_aparc_vol.columns = [str(col) + '_aparc' for col in stats_lh_aparc_vol.columns]\n",
    "stats_rh_aparc_area.columns = [str(col) + '_aparc' for col in stats_rh_aparc_area.columns]\n",
    "stats_lh_aparc_area.columns = [str(col) + '_aparc' for col in stats_lh_aparc_area.columns]\n",
    "stats_rh_aparc_thickness.columns = [str(col) + '_aparc' for col in stats_rh_aparc_thickness.columns]\n",
    "stats_lh_aparc_thickness.columns = [str(col) + '_aparc' for col in stats_lh_aparc_thickness.columns]\n",
    "stats_rh_aparc_thicknessstd.columns = [str(col) + '_aparc' for col in stats_rh_aparc_thicknessstd.columns]\n",
    "stats_lh_aparc_thicknessstd.columns = [str(col) + '_aparc' for col in stats_lh_aparc_thicknessstd.columns]\n",
    "\n",
    "# merge all of the stats data into one dataframe (based on first column)\n",
    "allstats_df = [stats_asegmean, stats_asegvol, stats_aseg_std, stats_rh_aparc_vol, stats_rh_aparc_area, stats_rh_aparc_thickness, stats_rh_aparc_thicknessstd, stats_lh_aparc_vol, stats_lh_aparc_area, stats_lh_aparc_thickness, stats_lh_aparc_thicknessstd]\n",
    "statsmerged_df = reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True, how='outer'), allstats_df).fillna('void')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go into each folder in /autofs/cluster/animal/scan_data/leads/recon_nip/SCAN_NOTES/ and add scannotes.csv to scaninfo (run, sequence name, dicom status,loni_series,loni_image)\n",
    "scannotes = pd.DataFrame(columns=['leads_id','mayo_notes','mayo_overallpass','download_date'])\n",
    "scanlist=[]\n",
    "sublist=[]\n",
    "runlist=[]\n",
    "errorlist=[]\n",
    "loniimgs = []\n",
    "loniseries = []\n",
    "# make a list of all dataframes then concatenate them after the for loop axis =1 \n",
    "directorylist = os.listdir(scandir)\n",
    "directorylist.sort()\n",
    "for file in directorylist:\n",
    "    if file.startswith(\"LDS\"):\n",
    "        sublist.append(file.split(\"_\")[0].lower())\n",
    "        df = pd.read_csv(scandir+file+'/scannotes.csv')\n",
    "        df2 = pd.read_csv(scandir+file+'/scaninfo.csv',header=None,names=['run','sequence_name','dicom_status','dim1','dim2','dim3','dim4','dicom_name'])\n",
    "        \n",
    "        # horizontal concatenation (a subject per loop iteration)\n",
    "        newdf = df[['leads_id','mayo_notes','mayo_overallpass','download_date']]\n",
    "        scanlist.append(newdf)\n",
    "        \n",
    "        # separate lists that will be appended as columns to final df (vertical concatenation); adds subject's run to list per iteration\n",
    "        runlist.append(df2['run'].values[0]) \n",
    "        errorlist.append(df2['dicom_status'].values[0])\n",
    "        \n",
    "        seqname = df2['dicom_name'].values[0]\n",
    "        loniimgs.append(re.findall(r\"_I(\\d{0,9}).dcm\",seqname)[0])\n",
    "        loniseries.append(re.findall(r\"_S(\\d{0,9})_\",seqname)[0])\n",
    "        \n",
    "allscans = pd.concat(scanlist, axis=0,ignore_index=True)\n",
    "allscans = allscans.sort_values(by=['leads_id'])\n",
    "allscans.reset_index(drop=True)\n",
    "\n",
    "# add runlist, errorlist, seqname, loniimgs, loniseries (vertical concat)\n",
    "allscans['run_number'] = runlist\n",
    "allscans['dicom_status'] = errorlist\n",
    "allscans['loni_image'] = loniimgs\n",
    "allscans['loni_series'] = loniseries\n",
    "allscans['subject_code'] = sublist\n",
    "\n",
    "#just extract subject_code and amyelg\n",
    "AMYSTATUS_df = AMYSTATUS_df[['subject_code','amyelg']]\n",
    "merged_Frame = pd.merge(allscans,AMYSTATUS_df, on='subject_code',how='outer')\n",
    "\n",
    "# extract Group, Sex, Age, Date, Description\n",
    "DOWNLOADS_df = DOWNLOADS_df[['Subject','Group','Sex','Age','Description','Acq Date']]\n",
    "DOWNLOADS_df = DOWNLOADS_df.rename(index=str, columns={\"Subject\": \"subject_code\"}) # rename Subject to subject_code for merging\n",
    "DOWNLOADS_df = DOWNLOADS_df.drop_duplicates(subset=['subject_code','Description'], keep=False)\n",
    "DOWNLOADS_df['subject_code'] = DOWNLOADS_df.subject_code.astype(str).str.lower()\n",
    "merged_Frame2 = pd.merge(merged_Frame,DOWNLOADS_df, on='subject_code',how='outer')\n",
    "\n",
    "RECON3T_QC = RECON3T_QC[['LEADS_ID','OVERALLQC','TEMPQC','FRONTQC','PARQC','INSULAQC','OCCQC','BGQC','CWMQC','VENTQC','LHIPQC','RHIPQC','COMMENTSQC','FS_INITIAL_COMMAND','FS_VERSION','STATUS_FINAL','EXCLUDE','REASON_EXCLUDE','EDITOR']]\n",
    "RECON3T_QC = RECON3T_QC.rename(index=str, columns={\"LEADS_ID\": \"leads_id\"})\n",
    "merged_Frame3 = pd.merge(merged_Frame2,RECON3T_QC, on='leads_id',how='outer')\n",
    "\n",
    "\n",
    "# NOW ADD THE STATS : add merged_Frame3 to statsmerged_df (column)\n",
    "# set statsmerged_df index (to numbers)\n",
    "statsmerged_df = statsmerged_df.reset_index()\n",
    "statsmerged_df = statsmerged_df.rename(index=str, columns={\"Measure:mean\": \"leads_id\"})\n",
    "# rename the first column to 'leads_id'\n",
    "EXTERNAL_DF = pd.merge(merged_Frame3,statsmerged_df, on='leads_id',how='outer')\n",
    "\n",
    "# save this final dataframe with the date:\n",
    "EXTERNAL_DF.to_csv(externalpath+'MGH_LEADS_DATASUMMARY_3T_'+time.strftime(\"%Y%m%d\")+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
