{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import io, os, sys, types # needed\n",
    "import glob # needed\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode # needed\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.pipeline.engine as pe\n",
    "from nipype.interfaces.freesurfer import MRIConvert\n",
    "#from IPython import get_ipython\n",
    "# from nbformat import read\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#import re\n",
    "\n",
    "# in nodes\n",
    "#import pandas as pd\n",
    "#import csv\n",
    "#from os import system # use sys\n",
    "\n",
    "\n",
    "#import subprocess\n",
    "#import getpass\n",
    "#from pathlib import Path\n",
    "#import shutil\n",
    "#import nipype.interfaces.utility as util # import the utility interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables\n",
    "\n",
    "leadsdir = '/cluster/animal/scan_data/leads/'\n",
    "dicomdir = \"/cluster/animal/scan_data/leads/LEADS/\"\n",
    "unpacklog = \"/autofs/cluster/animal/scan_data/leads/recon/unpack.log\"\n",
    "recondir = '/autofs/cluster/animal/scan_data/leads/recon_nip/'\n",
    "folders = [x for x in os.listdir(dicomdir) if not x.startswith(\".\")]\n",
    "subject = 'LDS0370007_20180801'\n",
    "\n",
    "# subjects with more than one MPRAGE:: these are the better QC ones:\n",
    "specialcases = {'LDS0370006':'/autofs/cluster/animal/scan_data/leads/LEADS/LDS0370006/Accelerated_Sagittal_MPRAGE/2018-07-26_10_41_42.0/S708999/',\n",
    "                'LDS0370007':'/autofs/cluster/animal/scan_data/leads/LEADS/LDS0370007/Accelerated_Sagittal_MPRAGE/2018-08-01_10_49_41.0/S711584/',\n",
    "                'LDS0370013': '/autofs/cluster/animal/scan_data/leads/LEADS/LDS0370013/Accelerated_Sagittal_MPRAGE/2018-08-22_08_55_38.0/S722833/'}\n",
    "\n",
    "# make a list of one dicom per unique series  (make into function and call during input)\n",
    "pickdicomlist = []\n",
    "alldicomdirs = glob.glob(dicomdir+'/*/Accelerated_Sagittal_MPRAGE/*/*/')\n",
    "for el in alldicomdirs:\n",
    "    splitstr = el.split('/')\n",
    "    if \"_\" not in splitstr[6]:\n",
    "        file =  os.listdir(el)[0] # pick any dicom\n",
    "        pickdicomlist.append(el+file)\n",
    "pickdicomlist\n",
    "\n",
    "# shortened version (not sure what this it needs)\n",
    "sh_dicomlist = []\n",
    "alldicomdirs = glob.glob(dicomdir+'/*/Accelerated_Sagittal_MPRAGE/*/*/')\n",
    "for el in alldicomdirs:\n",
    "    splitstr = el.split('/')\n",
    "    if \"_\" not in splitstr[6]:\n",
    "        file =  os.listdir(el)[0] # pick any dicom\n",
    "        sh_dicomlist.append(el+file)\n",
    "sh_dicomlist\n",
    "\n",
    "# define workflow\n",
    "leads_workflow = Workflow(name='leads_workflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE: CREATEDIR\n",
    "\n",
    "def createdir(val): # combined with find_dicom\n",
    "    import os\n",
    "    recondir = '/autofs/cluster/animal/scan_data/leads/recon_nip/'\n",
    "    subject = val.split('/')[6]\n",
    "    reconpath = recondir+subject\n",
    "    MPRAGE_path = val.rsplit('/',1)[0]+'/'\n",
    "    try:\n",
    "        imgpath = recondir+subject+'/mri/orig/'\n",
    "        os.makedirs(imgpath) # if it already exists, then it has already been run or has >1 session\n",
    "        dumplocation = imgpath+'001.mgz'\n",
    "        dicomlist = os.listdir(MPRAGE_path) #can be any number; choose 0\n",
    "        pickdicom = MPRAGE_path+dicomlist[0]\n",
    "    except(FileExistsError):\n",
    "        pass\n",
    "    #return subject, imgpath, reconpath, dicomlist, MPRAGE_path\n",
    "    return reconpath, MPRAGE_path, pickdicom, dumplocation\n",
    "\n",
    "\n",
    "CREATEDIR = pe.Node(Function(input_names=[\"val\"],\n",
    "                         output_names=[\"createdir_out1\",\"createdir_out2\", \"createdir_out3\", \"createdir_out4\"], # actual dicom (redundant to create unpacking node visualization)\n",
    "                         function=createdir),\n",
    "                        name='CREATEDIR')\n",
    "\n",
    "# CREATEDIR.inputs.val = '/cluster/animal/scan_data/leads/LEADS/LDS0370007/Accelerated_Sagittal_MPRAGE/2018-08-01_10_49_41.0/S711583/LEADS_LDS0370007_MR_Accelerated_Sagittal_MPRAGE__br_raw_20180801153311710_44_S711583_I1029697.dcm' # actual dicom\n",
    "# res = CREATEDIR.run()\n",
    "# print(res.outputs.createdir_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE : UNPACK\n",
    "\n",
    "def unpack(subjectdir, MPRAGE_path): # combine raw_dump and parse_scaninfo?\n",
    "    from os import system\n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    cmdstring = 'unpacksdcmdir -src %s -targ %s -scanonly %s/scan.info' % (MPRAGE_path, subjectdir, subjectdir)\n",
    "    system(cmdstring)\n",
    "    with open(subjectdir+'/scan.info', 'r') as in_file:\n",
    "        for line in in_file:\n",
    "            editline = line.split()\n",
    "            with open(subjectdir+'/scaninfo.csv', 'w') as result:\n",
    "                wr = csv.writer(result, dialect='excel')\n",
    "                wr.writerow(editline)\n",
    "            result.close()\n",
    "        in_file.close()\n",
    "    scan_info = pd.read_csv(subjectdir+'/scaninfo.csv', header=None)\n",
    "    return subjectdir[:-9], subjectdir\n",
    "\n",
    "UNPACK = pe.Node(Function(input_names=[\"subjectdir\",\"MPRAGE_path\"],\n",
    "                         output_names=[\"unpack_out1\",\"unpack_out2\"], # actual dicom (redundant to create unpacking node visualization)\n",
    "                         function=unpack),\n",
    "                        name='UNPACK')\n",
    "\n",
    "\n",
    "#UNPACK.inputs.MPRAGE_path = '/cluster/animal/scan_data/leads/LEADS/LDS0370007/Accelerated_Sagittal_MPRAGE/2018-08-01_10_49_41.0/S711583/' # actual dicom\n",
    "#UNPACK.inputs.subjectdir = '/autofs/cluster/animal/scan_data/leads/recon_nip/LDS0370007'\n",
    "\n",
    "# res = UNPACK.run()\n",
    "# print(res.outputs.unpack_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE : CONVERT2MGZ\n",
    "\n",
    "# because working in parallel to unpacking, it will convert dicoms that may have errors .. add node later to delete\n",
    "# unwanted dirs\n",
    "\n",
    "CONVERT2MGZ = pe.Node(MRIConvert(out_type='mgz'),\n",
    "                        name='CONVERT2MGZ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('/cluster/animal/scan_data/leads/LEADS/LDS0370007/Accelerated_Sagittal_MPRAGE/2018-08-01_10_49_41.0/S711583/LEADS_LDS0370007_MR_Accelerated_Sagittal_MPRAGE__br_raw_20180801153311710_44_S711583_I1029697.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Output Stream\n",
    "\n",
    "# # NODE : INFOSOURCE\n",
    "# # # a function free node to iterate over the list of subject names\n",
    "sh_dicomlist = '/cluster/animal/scan_data/leads/LEADS/LDS0370007/Accelerated_Sagittal_MPRAGE/2018-08-01_10_49_41.0/S711583/LEADS_LDS0370007_MR_Accelerated_Sagittal_MPRAGE__br_raw_20180801153311710_44_S711583_I1029697.dcm'   # might have to change this to subject ; date ; serial ?\n",
    "\n",
    "INFOSOURCE = Node(IdentityInterface(fields=['sh_dicomlist'], mandatory_inputs=False),\n",
    "                  name=\"INFOSOURCE\")\n",
    "\n",
    "INFOSOURCE.iterables = [('sh_dicomlist', sh_dicomlist)]  # got rid of iterables causing infinite loop\n",
    "##########################################\n",
    "\n",
    "# NODE : SELECTFILES\n",
    "templates = {'anat': sh_dicomlist}    # this is one dicom per session.. (before it was a nifti ; not sure if this works)\n",
    "              #'func': 'data/{subject_id}/run*.nii.gz'}\n",
    "\n",
    "SELECTFILES = Node(nio.SelectFiles(templates,\n",
    "                               base_directory=leadsdir),\n",
    "                   name=\"SELECTFILES\")\n",
    "\n",
    "########################################################\n",
    "\n",
    "# NODE : DATASINK\n",
    "DATASINK = Node(nio.DataSink(base_directory=leadsdir,\n",
    "                container='datasink_folder'),\n",
    "                name=\"DATASINK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect all nodes (including INFOSOURCE, SELECTFILES, and DATASINK) to workflow\n",
    "                        \n",
    "leads_workflow.connect([(INFOSOURCE, SELECTFILES, [('sh_dicomlist', 'sh_dicomlist')]),\n",
    "                 (SELECTFILES, CREATEDIR, [('anat', 'val')]),\n",
    "                 (CREATEDIR, UNPACK, [('createdir_out1', 'subjectdir')]),\n",
    "                 (CREATEDIR, UNPACK, [('createdir_out2', 'MPRAGE_path')]),\n",
    "                 (CREATEDIR, CONVERT2MGZ, [('createdir_out3', 'in_file')]),\n",
    "                 (CREATEDIR, CONVERT2MGZ, [('createdir_out4', 'out_file')]),\n",
    "                 (UNPACK, DATASINK, [('unpack_out1','leadsdir')]),\n",
    "                 (UNPACK, DATASINK, [('unpack_out2','recondir')])\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute your workflow in sequential way\n",
    "\n",
    "leads_workflow.run()\n",
    "\n",
    "# # Execute your workflow in parallel.\n",
    "# #   Use 4 cores on your local machine\n",
    "# workflow.run('MultiProc', plugin_args={'n_procs': 4})\n",
    "\n",
    "# #   Use a cluster environment to run your workflow\n",
    "# workflow.run('SGE', plugin_args={'qsub_args': '-q many'})\n",
    "\n",
    "# to visualize leads workflow\n",
    "\n",
    "#leads_workflow.write_graph(graph2use='flat')\n",
    "\n",
    "# make option to report status of all subjects (summary) and this workflow in latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_workflow.write_graph(graph2use='flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
