{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads MGH LEADS data into redcap's MASTER project. Uses the RECON_FLAIR pipeline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "from pydicom.tag import Tag\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import csv\n",
    "from redcap import Project, RedcapError\n",
    "import subprocess\n",
    "import datetime\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "api_url = 'https://redcap.partners.org/redcap/api/'\n",
    "api_key = '49E6305CE4B41073E2342F723C0F93F8'\n",
    "project = Project(api_url, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MGH_subjects = pd.read_csv('/autofs/cluster/animal/scan_data/leads/spreadsheets/IDENTIFICATION/MGH_SUBJECTS.csv')\n",
    "MGH_subjects = MGH_subjects.replace(np.nan, '', regex=True)\n",
    "# need to convert all columns with numbers to int --> str\n",
    "RECON_FLAIR_NOTES = pd.read_csv('/autofs/cluster/animal/scan_data/leads/recon_nip/RECON_FLAIR/recon_notes.csv')\n",
    "RECON_FLAIR_NOTES = RECON_FLAIR_NOTES.replace(np.nan, '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDS3600087_20190417\n",
      "static_arm_1\n",
      "WARNING: scan not on xnat\n"
     ]
    }
   ],
   "source": [
    "# put all subjects and add to the dtaframe so that all info is imported!\n",
    "sublist = #['LSWA_F_58_20190417'] \n",
    "\n",
    "for sub in sublist:\n",
    "    \n",
    "    name = sub.split(\"_\")[0]\n",
    "    date = sub.split(\"_\")[3]\n",
    "    date_sep = date[0:4]+'-'+date[4:6]+'-'+date[6:10]\n",
    "    \n",
    "    #obtain leads ID\n",
    "    subject_init = sub.split('_')\n",
    "    subject = subject_init[0]+'_'+subject_init[1]+'_'+subject_init[2]\n",
    "    data_frame = project.export_records(records=[subject],forms=['identification_numbers'],events=[('static_arm_1')],format='df')\n",
    "    try:\n",
    "        leads_id = 'LDS'+str(int(data_frame['leads_id'].values[0]))+'_'+date\n",
    "    except(ValueError):\n",
    "        leads_id = data_frame['leads_id'].values[0]+'_'+date\n",
    "    print(leads_id)\n",
    "    \n",
    "    # find the redcap arm according to the date of the scan\n",
    "    session_of_interest = project.export_records(records=[subject],forms=['scan_session'],format='df')\n",
    "    session_new = session_of_interest.reset_index()\n",
    "    find_arm = session_new[session_new['scan_date'] == date_sep]\n",
    "    arm = find_arm.loc[: , \"redcap_event_name\"].values[0]\n",
    "    print(arm)\n",
    "    \n",
    "    # export scan_session form content of specified arm\n",
    "    session_edit = project.export_records(records=[subject],forms=['scan_session'],events=[(arm)],format='df')\n",
    "    #session_edit = session_edit.reset_index()\n",
    "    \n",
    "    if MGH_subjects[MGH_subjects['dickerson_sessionid']==sub].XNAT_upload.values[0] == 0:\n",
    "        scan_uploaded_to_xnat = '0'\n",
    "        print('WARNING: scan not on xnat')\n",
    "    else:\n",
    "        scan_uploaded_to_xnat = '1'\n",
    "    scan_session_series_notes = MGH_subjects[MGH_subjects['dickerson_sessionid']==sub].notes.values[0]\n",
    "    \n",
    "    cmd = [ 'findsession', name]\n",
    "    output = subprocess.Popen( cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "    trials = [f for f in str(output).split(\"=======\") if ((\"SUBJECT\") in f)]\n",
    "\n",
    "    for trial in trials:\n",
    "        m = re.search('DATE   :  (.+?)TIME', trial)\n",
    "        found = m.group(1).replace(\",\",\"\").strip('\\\\n')\n",
    "        date_time_obj = datetime.datetime.strptime(found, '%B %d %Y')\n",
    "        date_redcapformat = str(date_time_obj.date())\n",
    "        date_conv = date_redcapformat.replace(\"-\",\"\")\n",
    "        if date_conv == date:\n",
    "            dpath = trial.split(':')[-1][:-1].strip('\\\\n').replace(\" \",\"\")\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # now set all variables that I will import\n",
    "    scan_upload_path = dpath\n",
    "    \n",
    "    #yes / no\n",
    "    scan_flag_for_review  = str(int((RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].FLAG_FOR_IR).values[0]))\n",
    "    \n",
    "    #notes\n",
    "    scan_flag_trigger = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].IR_TRIGGER).values[0]\n",
    "\n",
    "    # text (string)\n",
    "    recon1_qc_path = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].RECON_PATH).values[0]\n",
    "\n",
    "    # read in RECON_FLAIR notes\n",
    "    # 5_3_0, v5.3 | 6_beta, v6 beta | 6_0_0, v6.0 | dev, dev\n",
    "    FSV = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].FS_VERSION).values[0]\n",
    "    if float(FSV) == 6:\n",
    "        recon1_fsversion = '6_0_0'\n",
    "    else:\n",
    "        recon1_fsversion = ''\n",
    "\n",
    "    # 1, good | 2, okay | 3, bad | 4, unknown | 5, flag\n",
    "    recon_qc = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].Recon_Quality).values[0]\n",
    "    if recon_qc == 'good':\n",
    "        recon1_quality = '1'\n",
    "    elif recon_qc == 'okay':\n",
    "        recon1_quality = '2'\n",
    "    elif recon_qc == 'bad':\n",
    "        recon1_quality = '3'\n",
    "    elif (recon_qc == 'unknown') or (recon_qc == ''):\n",
    "        recon1_quality = '4'\n",
    "    elif recon_qc == 'flag':\n",
    "        recon1_quality = '5'\n",
    "    \n",
    "    # yes, yes | inprog, in progress | flag_needs_xopts, flag - needs troubleshooting/xopts | no, no | exclude, exclude from processing (ie. no highres T1)\n",
    "    recon_status = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].QC_STATUS).values[0]\n",
    "    if recon_status == 'complete':\n",
    "        recon1_qc_status = 'yes'\n",
    "    elif recon_status == 'error':\n",
    "        recon1_qc_status = 'flag_needs_xopts'\n",
    "    else:\n",
    "        recon1_qc_status = 'inprog'\n",
    "    \n",
    "    recon1_username = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].EDITOR).values[0]\n",
    "\n",
    "    recon1_qc_notes = (RECON_FLAIR_NOTES[RECON_FLAIR_NOTES['LEADS_ID']==leads_id].FS_QC_Notes).values[0]\n",
    "\n",
    "    # now use the pandas data frame but replace the value of interest ; then try importing.\n",
    "    \n",
    "    session_edit.loc[:,'scan_uploaded_to_xnat'] = scan_uploaded_to_xnat\n",
    "    #####session_edit.loc[session_edit['subject_id']==subject,'scan_session_series_notes'] = scan_session_series_notes\n",
    "    session_edit.loc[:,'scan_upload_path'] = scan_upload_path\n",
    "    session_edit.loc[:,'scan_flag_for_review'] = scan_flag_for_review\n",
    "    session_edit.loc[:,'scan_flag_trigger'] = scan_flag_trigger\n",
    "    session_edit.loc[:,'recon1_qc_path'] = recon1_qc_path\n",
    "    session_edit.loc[:,'recon1_fsversion'] = recon1_fsversion\n",
    "    session_edit.loc[:,'recon1_quality'] = recon1_quality\n",
    "    session_edit.loc[:,'recon1_qc_status'] = recon1_qc_status\n",
    "    session_edit.loc[:,'recon1_username'] = recon1_username\n",
    "    session_edit.loc[:,'recon1_qc_notes'] = recon1_qc_notes\n",
    "    session_edit.loc[:,'scan_uploaded_to_xnat'] = scan_uploaded_to_xnat\n",
    "    #import!\n",
    "    response = project.import_records(session_edit, date_format='YMD',format='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
